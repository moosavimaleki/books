
The beauty of such a gradual migration is that every stage of the process is easily reversible if
something goes wrong: you always have a working system to go back to. By reducing the risk of
irreversible damage, you can be more confident about going ahead, and thus move faster to improve
your system
[[11](ch12.html#Bartlett2015wv_ch12)]. ### The lambda architecture 
If batch processing is used to reprocess historical data, and stream processing is used to process
recent updates, then how do you combine the two? The lambda architecture
[[12](ch12.html#Marz2015th)]
is a proposal in this area that has gained a lot of attention. 
The core idea of the lambda architecture is that incoming data should be recorded by appending
immutable events to an always-growing dataset, similarly to event sourcing (see
[“Event Sourcing”](ch11.html#sec_stream_event_sourcing)). From these events, read-optimized views are derived. The lambda
architecture proposes running two different systems in parallel: a batch processing system such as
Hadoop MapReduce, and a separate stream-processing system such as Storm.