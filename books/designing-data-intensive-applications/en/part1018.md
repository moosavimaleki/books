*  If you can log an event to record the state of the system that the user saw before making a
decision, and give that event a unique identifier, then any later events can reference that event
identifier in order to record the causal dependency
[[4](ch12.html#Kerr2016va)].
We will return to this idea in [“Reads are events too”](#sec_future_read_events). *  Conflict resolution algorithms (see [“Automatic Conflict Resolution”](ch05.html#sidebar_conflict_resolution)) help with processing events
that are delivered in an unexpected order. They are useful for maintaining state, but they do not
help if actions have external side effects (such as sending a notification to a user). Perhaps, over time, patterns for application development will emerge that allow causal dependencies
to be captured efficiently, and derived state to be maintained correctly, without forcing all events
to go through the bottleneck of total order broadcast. ## Batch and Stream Processing 
I would say that the goal of data integration is to make sure that data ends up in the right form in
all the right places. Doing so requires consuming inputs, transforming, joining, filtering,
aggregating, training models, evaluating, and eventually writing to the appropriate outputs. Batch
and stream processors are the tools for achieving this goal.