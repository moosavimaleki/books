### Responsibility and accountability 
Automated decision making opens the question of responsibility and accountability
[[87](ch12.html#ONeil2016vh)]. If a human makes a mistake, they can be
held accountable, and the person affected by the decision can appeal. Algorithms make mistakes too,
but who is accountable if they go wrong
[[88](ch12.html#Angwin2016qn)]? When a self-driving car
causes an accident, who is responsible? If an automated credit scoring algorithm systematically
discriminates against people of a particular race or religion, is there any recourse? If a decision
by your machine learning system comes under judicial review, can you explain to the judge how the
algorithm made its decision? 
Credit rating agencies are an old example of collecting data to make decisions about people. A bad
credit score makes life difficult, but at least a credit score is normally based on relevant facts
about a personâ€™s actual borrowing history, and any errors in the record can be corrected (although
the agencies normally do not make this easy). However, scoring algorithms based on machine learning
typically use a much wider range of inputs and are much more opaque, making it harder to understand
how a particular decision has come about and whether someone is being treated in an unfair or
discriminatory way [[89](ch12.html#Goodman2016vd)].