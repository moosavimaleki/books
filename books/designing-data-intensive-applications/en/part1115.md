A credit score summarizes “How did you behave in the past?” whereas predictive analytics usually
work on the basis of “Who is similar to you, and how did people like you behave in the past?”
Drawing parallels to others’ behavior implies stereotyping people, for example based on where they
live (a close proxy for race and socioeconomic class). What about people who get put in the wrong
bucket? Furthermore, if a decision is incorrect due to erroneous data, recourse is almost impossible
[[87](ch12.html#ONeil2016vh)]. Much data is statistical in nature, which means that even if the probability distribution on the
whole is correct, individual cases may well be wrong. For example, if the average life expectancy in
your country is 80 years, that doesn’t mean you’re expected to drop dead on your 80th birthday.
From the average and the probability distribution, you can’t say much about the age to which one
particular person will live. Similarly, the output of a prediction system is probabilistic and may
well be wrong in individual cases.