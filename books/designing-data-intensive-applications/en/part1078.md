### Applying end-to-end thinking in data systems 
This brings me back to my original thesis: just because an application uses a data system that
provides comparatively strong safety properties, such as serializable transactions, that does not
mean the application is guaranteed to be free from data loss or corruption. The application itself
needs to take end-to-end measures, such as duplicate suppression, as well. That is a shame, because fault-tolerance mechanisms are hard to get right. Low-level reliability
mechanisms, such as those in TCP, work quite well, and so the remaining higher-level faults occur
fairly rarely. It would be really nice to wrap up the remaining high-level fault-tolerance machinery
in an abstraction so that application code needn’t worry about it—but I fear that we have not yet
found the right abstraction. Transactions have long been seen as a good abstraction, and I do believe that they are useful. As
discussed in the introduction to [Chapter 7](ch07.html#ch_transactions), they take a wide range of possible issues
(concurrent writes, constraint violations, crashes, network interruptions, disk failures) and
collapse them down to two possible outcomes: commit or abort. That is a huge simplification of the
programming model, but I fear that it is not enough.