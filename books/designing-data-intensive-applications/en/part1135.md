# Summary 
In this chapter we discussed new approaches to designing data systems, and I included my personal
opinions and speculations about the future. We started with the observation that there is no one
single tool that can efficiently serve all possible use cases, and so applications necessarily need
to compose several different pieces of software to accomplish their goals. We discussed how to solve
this data integration problem by using batch processing and event streams to let data changes flow
between different systems. In this approach, certain systems are designated as systems of record, and other data is derived
from them through transformations. In this way we can maintain indexes, materialized views, machine
learning models, statistical summaries, and more. By making these derivations and transformations
asynchronous and loosely coupled, a problem in one area is prevented from spreading to unrelated
parts of the system, increasing the robustness and fault-tolerance of the system as a whole.