
The outputs of batch and stream processes are derived datasets such as search indexes, materialized
views, recommendations to show to users, aggregate metrics, and so on (see [“The Output of Batch Workflows”](ch10.html#sec_batch_output) and
[“Uses of Stream Processing”](ch11.html#sec_stream_uses)). As we saw in [Chapter 10](ch10.html#ch_batch) and [Chapter 11](ch11.html#ch_stream), batch and stream processing have a lot of principles in
common, and the main fundamental difference is that stream processors operate on unbounded datasets
whereas batch process inputs are of a known, finite size. There are also many detailed differences
in the ways the processing engines are implemented, but these distinctions are beginning to blur. 
Spark performs stream processing on top of a batch processing engine by breaking the stream into
microbatches, whereas Apache Flink performs batch processing on top of a stream processing engine
[[5](ch12.html#Tzoumas2015tn)].
In principle, one type of processing can be emulated on top of the other, although the performance
characteristics vary: for example, microbatching may perform poorly on hopping or sliding windows
[[6](ch12.html#Kim2016uw)].