As we saw in the last section, reliable stream processing systems can preserve integrity without
requiring distributed transactions and an atomic commit protocol, which means they can potentially
achieve comparable correctness with much better performance and operational robustness. We achieved
this integrity through a combination of mechanisms: *  
Representing the content of the write operation as a single message, which can easily be written
atomically—an approach that fits very well with event sourcing (see [“Event Sourcing”](ch11.html#sec_stream_event_sourcing)) *  
Deriving all other state updates from that single message using deterministic derivation
functions, similarly to stored procedures (see [“Actual Serial Execution”](ch07.html#sec_transactions_serial) and
[“Application code as a derivation function”](#sec_future_dataflow_derivation)) *  Passing a client-generated request ID through all these levels of processing, enabling end-to-end
duplicate suppression and idempotence *  Making messages immutable and allowing derived data to be reprocessed from time to time,
which makes it easier to recover from bugs (see [“Advantages of immutable events”](ch11.html#sec_stream_immutability_pros))