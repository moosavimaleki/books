Naturally, payment networks want to prevent fraudulent transactions, banks want to avoid bad loans,
airlines want to avoid hijackings, and companies want to avoid hiring ineffective or untrustworthy
people. From their point of view, the cost of a missed business opportunity is low, but the cost of
a bad loan or a problematic employee is much higher, so it is natural for organizations to want to
be cautious. If in doubt, they are better off saying no. However, as algorithmic decision-making becomes more widespread, someone who has (accurately or
falsely) been labeled as risky by some algorithm may suffer a large number of those “no” decisions.
Systematically being excluded from jobs, air travel, insurance coverage, property rental, financial
services, and other key aspects of society is such a large constraint of the individual’s freedom
that it has been called “algorithmic prison”
[[82](ch12.html#Davidow2014ve)].
In countries that respect human rights, the criminal justice system presumes innocence until proven
guilty; on the other hand, automated systems can systematically and arbitrarily exclude a person
from participating in society without any proof of guilt, and with little chance of appeal.