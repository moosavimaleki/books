*  Since the stream pipeline and the batch pipeline produce separate outputs, they need to be merged
in order to respond to user requests. This merge is fairly easy if the computation is a simple
aggregation over a tumbling window, but it becomes significantly harder if the view is derived
using more complex operations such as joins and sessionization, or if the output is not a time
series. *  
Although it is great to have the ability to reprocess the entire historical dataset, doing so
frequently is expensive on large datasets. Thus, the batch pipeline often needs to be set up to
process incremental batches (e.g., an hour’s worth of data at the end of every hour) rather than
reprocessing everything. This raises the problems discussed in [“Reasoning About Time”](ch11.html#sec_stream_time), such as
handling stragglers and handling windows that cross boundaries between batches. Incrementalizing
a batch computation adds complexity, making it more akin to the streaming layer, which runs
counter to the goal of keeping the batch layer as simple as possible.