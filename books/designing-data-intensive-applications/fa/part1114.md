### مسئولیت و پاسخگویی
تصمیم‌گیری خودکار سؤال مسئولیت و پاسخگویی را مطرح می‌کند [[87](ch12.html#ONeil2016vh)]. اگر یک انسان اشتباه کند، می‌توان او را پاسخگو دانست، و فردی که تحت تأثیر تصمیم قرار گرفته است می‌تواند درخواست تجدیدنظر کند. الگوریتم‌ها نیز اشتباه می‌کنند، اما اگر اشتباه کنند چه کسی پاسخگو است [[88](ch12.html#Angwin2016qn)]؟ وقتی یک خودروی خودران باعث تصادف می‌شود، چه کسی مسئول است؟ اگر یک الگوریتم امتیازدهی اعتباری خودکار به طور سیستماتیک علیه افرادی از یک نژاد یا مذهب خاص تبعیض قائل شود، آیا راه چاره‌ای وجود دارد؟ اگر تصمیمی توسط سیستم یادگیری ماشینی شما تحت بررسی قضایی قرار گیرد، آیا می‌توانید به قاضی توضیح دهید که الگوریتم چگونه تصمیم خود را گرفته است؟

آژانس‌های رتبه‌بندی اعتباری نمونه قدیمی از جمع‌آوری داده برای تصمیم‌گیری درباره افراد هستند. یک امتیاز اعتباری بد زندگی را دشوار می‌کند، اما حداقل یک امتیاز اعتباری معمولاً بر اساس واقعیت‌های مربوط به تاریخچه واقعی وام‌گیری یک فرد است، و هر گونه خطا در سابقه می‌تواند اصلاح شود (اگرچه آژانس‌ها معمولاً این کار را آسان نمی‌کنند). با این حال، الگوریتم‌های امتیازدهی مبتنی بر یادگیری ماشینی معمولاً از طیف بسیار گسترده‌تری از ورودی‌ها استفاده می‌کنند و بسیار مبهم‌تر هستند، که درک اینکه یک تصمیم خاص چگونه به وجود آمده و آیا با کسی به شیوه‌ای ناعادلانه یا تبعیض‌آمیز رفتار می‌شود را دشوارتر می‌کند [[89](ch12.html#Goodman2016vd)].