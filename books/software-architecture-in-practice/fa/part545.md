For systems running with a single data center, timeouts and thresholds can be set aggressively, since network delays are minimal and missed responses are likely due to software crashes or hardware failures. In contrast, for systems operating over a wide area network, a cellular radio network, or even a satellite link, more thought should be put into setting the parameters, as these systems may experience intermittent but longer network delays. In such cases, the parameters may be relaxed to reflect this possibility and avoid triggering unnecessary recovery actions. #### Long Tail Latency Regardless of whether the cause is an actual failure or just a slow response, the response to your original request may exhibit what is called long tail latency. [Figure 17.3](ch17.xhtml#ch17fig03) shows a histogram of the latency of 1,000 “launch instance” requests to Amazon Web Services (AWS). Notice that some requests took a very long time to satisfy. When evaluating measurement sets such as this one, you must be careful which statistic you use to characterize the data set. In this case, the histogram peaks at a latency of 22 seconds; however, the average latency over all the measurements is 28 seconds, and the median latency (half the requests are completed with latency less than this value) is 23 seconds. Even after a latency of 57 seconds, 5 percent of the requests have still not been completed (i.e., the 95th percentile is 57 seconds). So, although the mean latency for each service-to-service request to a cloud-based service may be within tolerable limits, a reasonable number of these requests can have much greater latency—in this case, from 2 to 10 times longer than the average. These are the measurements in the long tail on the right side of the histogram.